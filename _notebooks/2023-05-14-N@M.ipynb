{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Translating Realtime Human Facial Expressions to an Emoji through a Trained CNN Algorithm <h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Project Overview</h2>\n",
    "\n",
    "1. Project Purpose/Description\n",
    "2. Tool/Environment Setup \n",
    "3. Theory Exploration (ML, NN, CNNs)\n",
    "4. Train data \n",
    "4. Create Model\n",
    "5. Compile Model\n",
    "6. Train Model\n",
    "7. Implement GUI \n",
    "8. Debugging\n",
    "9. Reflection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><mark>#1</mark> Project Goals/Description</h2>\n",
    "\n",
    "The goal of this project is to create a model capable of detecting human emotion through a realtime web cam and match the expression with a corresponding emoji. \n",
    "\n",
    "For that we use a dataset containing more than 28700 images that is already classified in one of these 7 categories: angry, disgust, fear, happy, neutral, sad, and surprise. \n",
    "\n",
    "We are going to create a machine learning algorithm, specifically a Convolutional Neural Network (CNN), with the platform Tensorflow to train the model based on this data to recognize facial expressions and map those same emotions on an emoji. \n",
    "\n",
    "> Integrating the model with the frontend should result in a functionality that looks like this!\n",
    "\n",
    "![](https://i.imgur.com/XbjHSkG.png)\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><mark>#2</mark> Tool/Environment Setup</h2>\n",
    "\n",
    "<h3>Some tools/topics covered</h3>\n",
    "\n",
    "- Language: Python\n",
    "\n",
    "- Deep Neural Networks (Tensorflow)\n",
    "\n",
    "- Python Packages (Keras)\n",
    "\n",
    "<h3>1. VSCode Environment</h3>\n",
    "\n",
    "(a) Create a new folder in File Explorer and name it *Project Name*. Make sure you know the directory path\n",
    "\n",
    "(b) Open the folder in VSCODE \n",
    "\n",
    "(c) Create a new folder called \"src\" and two new files called \"train.py\" and \"emoji.py\". \n",
    "\n",
    "(d) Now create 2 subfolders under \"src\" called \"data\" and \"emojis\". \n",
    "\n",
    "(e) Navigate to [this dataset](https://www.kaggle.com/datasets/msambare/fer2013) on Kaggle and download it. We will be using this dataset to train our model so look around and familiarize yourself with what this data is!\n",
    "\n",
    "(f) Download and extract the data into the \"data\" folder. You should now be able to see two subset folders labeled \"train\" and \"test\" folders with many pictures under the \"data\" folder. \n",
    "\n",
    "We will be filling in the emojis folder later. This is all you need to set up for now!\n",
    "\n",
    "\n",
    "<h3>2. Modules to Install</h3>\n",
    "\n",
    "- <b>OpenCV</b>: Otherwie known as Open Source Computer Vision. A library that provides a set of tools/functions to process/analyze images and videos \n",
    "\n",
    "- <b>Numpy</b>: Python library that allows us to use multi-dimensional rrays to store large datasets and use optimized mathematical functions for data analysis\n",
    "\n",
    "- <b>Tensorflow</b>: A very useful tool for machine learning. Takes data, builds a model, trains it, and then lets us use the trained model to make predictions!\n",
    "\n",
    "- <b>Keras</b>: A high-level neural networks API integrated into Tensorflow\n",
    "\n",
    "Run these commands in terminal to install. These packages will later be used when compiling and training the model. \n",
    "\n",
    "> FOR WINDOWS \n",
    "\n",
    "    pip install opencv-python\n",
    "\n",
    "    pip install numpy==1.22\n",
    "\n",
    "    pip install tensorflow==2.12.0 \n",
    "    \n",
    "    pip install keras==2.12.0\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><mark>#3</mark> Theory Exploration: Machine Learning & Neural Networks </h2>\n",
    "\n",
    "<h3>Machine Learning</h3>\n",
    "\n",
    "![](https://i.imgur.com/w8bT2HJ.png)\n",
    "\n",
    "- The term <nark>machine learning</mark> has become a buzz word used by all those interested or knowledgable about the tech world. But what really is it? \n",
    "\n",
    "- To put it simply, machine learning is like <b>teaching a computer to learn things by itself</b>. Just like how a child is able to recognize what a dog is after many experiences of seeing or playing with a dog, if we show a computer lots of pictures of animals and tell it which animal is which, the computer will learn to recognize those animals by itself when given new pictures. \n",
    "\n",
    "- Thus, machine learning is a way for computers to detect patterns and make predictions based on data rather than being explicitly programmed to do a certain task. \n",
    "\n",
    "<h3>Neural Networks</h3>\n",
    "\n",
    "![](https://i.imgur.com/3bORFz5.png)\n",
    "\n",
    "- A <mark>Neural Network</mark> is a type of machine learning model. It has 3 main types of layers: input, hidden, and output. It is designed <b>to work like a human brain by processing information through layers of connected neurons</b>. \n",
    "\n",
    "    - Each neuron recieves input, processes it, and then sends an output to the next layer of neurons. \n",
    "\n",
    "    - Each layer learns to identify increasingly complex features and patterns, building on the features learned by the previous layers. For example, in an image recognition task the 1st layer might learn to identify simple features such as edges/corners and in the next layer it might learn to identify more complex features such as curves or textures that are made up of these simple features. \n",
    "\n",
    "- In the picture above is an example of a <mark>Deep Neural Network</mark>, which is just a neural network with more than 2 hidden layers. These hidden layers are where most of the computations are made to identify patterns in the data and make predictions. The more # of hidden layers, the more the neural network is able to learn and recognize more COMPLEX patterns in the input data. \n",
    "\n",
    "<h3>Why are we using a Deep Convolutional Neural Network (CNN)? </h3>\n",
    "\n",
    "![](https://i.imgur.com/3RO81Ua.png)\n",
    "\n",
    "- A <mark>Convolutional Neural Network</mark> is a type of neural network that is <b>IDEAL for image classification</b> because it is specifically designed to recognize patterns and features within images \n",
    "    - Usually after the convolutional layers, there are <b>pooling layers</b> that look at small areas of the image, and then take the max/avg value in that area. This reduces the number of pixels in the image while keeping the most important info about the features for pattern recognition! \n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><mark>#4</mark> More imports & Data Preprocessing </h2>\n",
    "\n",
    "Navigate to the <b>train.py file</b>\n",
    "\n",
    "<h3>1. Import Packages </h3>\n",
    "\n",
    "> \n",
    "    import numpy as np \n",
    "    from tensorflow import keras                                    \n",
    "    from keras.models import Sequential, load_model                   \n",
    "    from keras.layers import Dense, Dropout, Flatten\n",
    "    from keras.layers import Conv2D\n",
    "    from keras.optimizers import Adam\n",
    "    from keras.layers import MaxPooling2D\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "We will learn about what these functions do soon~\n",
    "\n",
    "-------------------------------------------------------------\n",
    "\n",
    "<b>Before we can even start making our model, we need to pre-process our data. We will be rescaling, applying filters, and resizing the images to be compatible for NN training</b>\n",
    "\n",
    "<h3>2. Train data </h3>\n",
    "\n",
    "#Define the directories where training/testing data located\n",
    ">\n",
    "    train_dir = 'data/train'\n",
    "    value_dir = 'data/test'\n",
    "\n",
    "#Divides image pixel values by 255 to scale down pixel values to normalized range between 0 and 1 for NN training\n",
    "\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    value_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "#Loads images from train_dir\n",
    ">  \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "\n",
    "#Resize images to 48 x 48 pixels \n",
    ">\n",
    "        target_size = (48, 48),\n",
    "\n",
    "#Number of images processed in each batch \n",
    ">\n",
    "        batch_size = 64,\n",
    "\n",
    "#Convert images to grayscale (reduce dimensionality of input data from RGB to intensity)\n",
    ">\n",
    "        color_mode = \"grayscale\",\n",
    "\n",
    "#Labels for images are categorical values (Ex. Happy, Sad, Surprised, etc)\n",
    ">\n",
    "        class_mode = 'categorical'\n",
    "        )\n",
    "#Same process for test data    \n",
    ">    \n",
    "    value_generator = value_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size = (48, 48),\n",
    "        batch_size = 64,\n",
    "        color_mode = \"grayscale\",\n",
    "        class_mode = 'categorical'\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><mark>#5</mark> Create Model </h2>\n",
    "\n",
    "Continue in the train.py file. \n",
    "\n",
    "We can now start building our Convolutional Neural Network layer by layer using the sequential model.\n",
    "\n",
    "In order to create an <b>accurate</b> model, we are going to implement many convolutional layers to detect complex patterns, pooling layers to downsample the data, regularization techniques to prevent overfitting, flatten layers to prepare for fully connected layers, and dense layers to prepare for classification using activation functions.\n",
    "<hr>\n",
    "\n",
    ">\n",
    "    emotion_model = Sequential()\n",
    "\n",
    "#Adding 2 convolutional layers that are responsible for detecting local patterns in the input data\n",
    "#1st layer has 32 filters of size 3x3 pixels and applies the ReLU activation function, 2nd is the same except has 64 filters that allows the model to extract more complex patterns\n",
    "> \n",
    "    emotion_model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "    emotion_model.add(Conv2D(64, kernel_size = (3,3), activation = 'relu'))\n",
    "\n",
    "#Pooling layers: Downsample data to look at small areas of the image (reduces spatial dimensions while retaining important features)\n",
    ">\n",
    "    emotion_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Regularization: Randomly sets input units to 0 to prevent overfitting (learn noise rather than actual signal)\n",
    ">\n",
    "    emotion_model.add(Dropout(0.25))\n",
    "\n",
    "#More convolutional/pooling layers and regularization\n",
    ">\n",
    "    emotion_model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "    emotion_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    emotion_model.add(Conv2D(128, kernel_size=(3,3), activation = 'relu'))\n",
    "    emotion_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    emotion_model.add(Dropout(0.25))\n",
    "\n",
    "#Reshapes ouput from previous layers into 1D vector to prepare for the fully connected layers\n",
    ">\n",
    "    emotion_model.add(Flatten())\n",
    "\n",
    "#1st dense layer: 1024 neurons fully connected layer\n",
    ">\n",
    "    emotion_model.add(Dense(1024, activation='relu'))\n",
    "    emotion_model.add(Dropout(0.5))\n",
    "\n",
    "#2nd dense layer: 7 neurons which is # of possible output classes (emotions)\n",
    "#Uses softmax activation function to convert final layer's raw predicted values into a probability distribution over the different classes for classification\n",
    ">\n",
    "    emotion_model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><mark>#6</mark> Compile the Model </h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- cd into src folder --> python train.py in terminal \n",
    "*compiling*\n",
    "\n",
    "![](https://i.imgur.com/0WzdMVU.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dense layer: Each neuron in the layer is connected to EVERY neuron in the previous layer\n",
    "- Drop out Layer: Randomly deactivates neurons to prevent a model that becomes too specialized and preforms extremely well on the training data but fails to generalize and make accurate predictions on new, unseen data \n",
    "- Flatten layer: Takes complex, structured data (images) and makes its impler by converting it into a flat, 1D array. Useful when transitioning from convolutionl/pooling layers to subsequent layers to process the data as a simpler, linear sequence. Easier for NN to learn patterns and make predictions \n",
    "- Keras: Sequential vs Functional\n",
    "    - Sequential (Create model layer by layer)\n",
    "    - Functional (A layer can connect to any layer, much more complex)\n",
    "- CNN: Simple pplication of filter to an input that results in an activation. Certain inputs and thresholds. When Input meets those thresholds there is an activation \n",
    "- Certain type of input --> repeats itself --> feature map forms\n",
    "- Activation function: mathematical func that determines whether the neuron should be activated based on the input it recieves. Introduces non-linearity to the network, allowing it to learn and model complex relationships between input data and output predictions \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "emoji.py \n",
    "\n",
    "imports \n",
    "install imagemagick\n",
    "\n",
    "Finished training \n",
    "\n",
    "![](https://i.imgur.com/SkgIxW5.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
